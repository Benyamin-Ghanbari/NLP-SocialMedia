{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99450f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from xgboost import XGBClassifier\n",
    "import emoji\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dcb9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>fullname</th>\n",
       "      <th>username</th>\n",
       "      <th>biography</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>following_count</th>\n",
       "      <th>is_business</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>is_private</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>man</td>\n",
       "      <td>2</td>\n",
       "      <td>Farshid</td>\n",
       "      <td>mr_gh_farshid</td>\n",
       "      <td>دردا ک در این بادیه بسیار دویدیم...\\nGlory man...</td>\n",
       "      <td>1604.0</td>\n",
       "      <td>1407.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>woman</td>\n",
       "      <td>2</td>\n",
       "      <td>zahr@72</td>\n",
       "      <td>zahra.roozbahani72</td>\n",
       "      <td>خواهی که زکوچ در امان برگردی\\nباید که به جان ,...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woman</td>\n",
       "      <td>2</td>\n",
       "      <td>ms farahnaz♥</td>\n",
       "      <td>___lady.farahnazi.__</td>\n",
       "      <td>Having you,  is all I wish for \\nداشتنت، تمامِ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>woman</td>\n",
       "      <td>1</td>\n",
       "      <td>Lena.mommy farzan</td>\n",
       "      <td>mommy.lena3361</td>\n",
       "      <td>دردونه من لنا کوچولو</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woman</td>\n",
       "      <td>2</td>\n",
       "      <td>Narsis Asadollahi</td>\n",
       "      <td>_l.aurora.l_</td>\n",
       "      <td>I am an animation student\\n🎧🎼🎨⚓️🤍 \\n@general.m...</td>\n",
       "      <td>200.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>woman</td>\n",
       "      <td>2</td>\n",
       "      <td>Ŋεgɨŋ</td>\n",
       "      <td>negiiin_bahrmandi</td>\n",
       "      <td>﷽\\nAllah IS Enough FoR Me?\\n♥️?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>man</td>\n",
       "      <td>3</td>\n",
       "      <td>h🗯abdi🗯offìcial</td>\n",
       "      <td>h.abdi.official</td>\n",
       "      <td>حقوقی</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>woman</td>\n",
       "      <td>2</td>\n",
       "      <td>⚜رویا احمدی⚜</td>\n",
       "      <td>roya.ahmadi.k</td>\n",
       "      <td>مهندس صنایع👩‍🔧🏭 Industrial engineer\\nمعمار👩‍💻👷...</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>man</td>\n",
       "      <td>3</td>\n",
       "      <td>لرستان &amp;خرم اباد</td>\n",
       "      <td>erfanpouersif</td>\n",
       "      <td>khoramabad</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>man</td>\n",
       "      <td>4</td>\n",
       "      <td>Sasan</td>\n",
       "      <td>sasan.zeinoddin</td>\n",
       "      <td>Sport 🏃🏻‍♂️🏊🏼‍♂️🚴🏽‍♂️\\nCivil Engineer🗽\\nKurdis...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  age           fullname              username  \\\n",
       "0       man    2            Farshid         mr_gh_farshid   \n",
       "1     woman    2            zahr@72    zahra.roozbahani72   \n",
       "2     woman    2       ms farahnaz♥  ___lady.farahnazi.__   \n",
       "3     woman    1  Lena.mommy farzan        mommy.lena3361   \n",
       "4     woman    2  Narsis Asadollahi          _l.aurora.l_   \n",
       "...     ...  ...                ...                   ...   \n",
       "7995  woman    2              Ŋεgɨŋ     negiiin_bahrmandi   \n",
       "7996    man    3    h🗯abdi🗯offìcial       h.abdi.official   \n",
       "7997  woman    2       ⚜رویا احمدی⚜         roya.ahmadi.k   \n",
       "7998    man    3   لرستان &خرم اباد         erfanpouersif   \n",
       "7999    man    4              Sasan       sasan.zeinoddin   \n",
       "\n",
       "                                              biography  follower_count  \\\n",
       "0     دردا ک در این بادیه بسیار دویدیم...\\nGlory man...          1604.0   \n",
       "1     خواهی که زکوچ در امان برگردی\\nباید که به جان ,...            67.0   \n",
       "2     Having you,  is all I wish for \\nداشتنت، تمامِ...             0.0   \n",
       "3                                  دردونه من لنا کوچولو             0.0   \n",
       "4     I am an animation student\\n🎧🎼🎨⚓️🤍 \\n@general.m...           200.0   \n",
       "...                                                 ...             ...   \n",
       "7995                    ﷽\\nAllah IS Enough FoR Me?\\n♥️?             0.0   \n",
       "7996                                              حقوقی             0.0   \n",
       "7997  مهندس صنایع👩‍🔧🏭 Industrial engineer\\nمعمار👩‍💻👷...          1260.0   \n",
       "7998                                         khoramabad             0.0   \n",
       "7999  Sport 🏃🏻‍♂️🏊🏼‍♂️🚴🏽‍♂️\\nCivil Engineer🗽\\nKurdis...             0.0   \n",
       "\n",
       "      following_count  is_business  is_verified  is_private  \n",
       "0              1407.0          0.0          0.0         0.0  \n",
       "1               501.0          0.0          0.0         0.0  \n",
       "2                 0.0          0.0          0.0         0.0  \n",
       "3                 0.0          0.0          0.0         0.0  \n",
       "4               328.0          0.0          0.0         0.0  \n",
       "...               ...          ...          ...         ...  \n",
       "7995              0.0          0.0          0.0         0.0  \n",
       "7996              0.0          1.0          0.0         0.0  \n",
       "7997           1167.0          0.0          0.0         0.0  \n",
       "7998              0.0          0.0          0.0         0.0  \n",
       "7999              0.0          0.0          0.0         0.0  \n",
       "\n",
       "[8000 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab977f",
   "metadata": {},
   "source": [
    "### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87b15340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   gender           8000 non-null   object \n",
      " 1   age              8000 non-null   int64  \n",
      " 2   fullname         8000 non-null   object \n",
      " 3   username         8000 non-null   object \n",
      " 4   biography        8000 non-null   object \n",
      " 5   follower_count   8000 non-null   float64\n",
      " 6   following_count  8000 non-null   float64\n",
      " 7   is_business      7997 non-null   float64\n",
      " 8   is_verified      8000 non-null   float64\n",
      " 9   is_private       8000 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(4)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# do some preprocessing :)\n",
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4becbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   age              2000 non-null   int64  \n",
      " 1   fullname         2000 non-null   object \n",
      " 2   username         2000 non-null   object \n",
      " 3   biography        2000 non-null   object \n",
      " 4   follower_count   2000 non-null   float64\n",
      " 5   following_count  2000 non-null   float64\n",
      " 6   is_business      2000 non-null   float64\n",
      " 7   is_verified      2000 non-null   float64\n",
      " 8   is_private       2000 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(3)\n",
      "memory usage: 140.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49348ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender  is_business\n",
       "man     0.0            3475\n",
       "        1.0             524\n",
       "woman   0.0            3696\n",
       "        1.0             302\n",
       "Name: is_business, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['gender'])['is_business'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c09b9e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender  is_private\n",
       "man     0.0           4000\n",
       "woman   0.0           3999\n",
       "        1.0              1\n",
       "Name: is_private, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['gender'])['is_private'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183bb413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "man      2963.39175\n",
       "woman    2527.00875\n",
       "Name: follower_count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['gender'])['follower_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20c89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "man      900.5085\n",
       "woman    523.9045\n",
       "Name: following_count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['gender'])['following_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b9ddac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_business'].fillna(train['is_business'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9eff4d",
   "metadata": {},
   "source": [
    "### Feature Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43826191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lenght of biography on Train data\n",
    "\n",
    "train['len_bio'] = train['biography'].apply(len)\n",
    "    \n",
    "# Lenght of biography on Test data \n",
    "\n",
    "test['len_bio'] = test['biography'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3f01c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to count emojis in a string\n",
    "def count_emojis(text):\n",
    "    return emoji.emoji_count(text)\n",
    "\n",
    "# Adding a new column to store the count of emojis in the 'biography' column\n",
    "train['emoji_count'] = train['biography'].apply(count_emojis)\n",
    "test['emoji_count']=test['biography'].apply(count_emojis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e83fdd",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c46a46e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['fullname', 'username','biography','len_bio','emoji_count','age','is_business','follower_count', 'following_count']]\n",
    "y = train['gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194abd13",
   "metadata": {},
   "source": [
    "### Implemention Of NLP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f6245",
   "metadata": {},
   "source": [
    "##### I generate two model , First model Predict and Detect gender based on 'fullname', 'username','biography' ( Text model ) and i use the answer of the this model as a new feature for my Second model that is geneated by the others feature like 'len_bio','emoji_count','age', Etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb8886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\benya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\benya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9b684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing for NLP analysis\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and punctuation\n",
    "    tokens = [word.lower() for word in tokens if word.isalnum() and word.lower() not in stopwords.words('english')]\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3cff331",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benya\\AppData\\Local\\Temp\\ipykernel_6068\\1503882210.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['fullname'] = X['fullname'].apply(preprocess_text)\n",
      "C:\\Users\\benya\\AppData\\Local\\Temp\\ipykernel_6068\\1503882210.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['username'] = X['username'].apply(preprocess_text)\n",
      "C:\\Users\\benya\\AppData\\Local\\Temp\\ipykernel_6068\\1503882210.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['biography'] = X['biography'].apply(preprocess_text)\n"
     ]
    }
   ],
   "source": [
    "# Apply text preprocessing to each column containing text data\n",
    "X['fullname'] = X['fullname'].apply(preprocess_text)\n",
    "X['username'] = X['username'].apply(preprocess_text)\n",
    "X['biography'] = X['biography'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9e07e5",
   "metadata": {},
   "source": [
    "### First model : Text model based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b74e0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_text_feature = X[['fullname', 'username','biography']] \n",
    "x_train, x_val, y_train, y_val = train_test_split(X_text_feature, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8e6ee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_model = SVC()\n",
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ec448b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benya\\AppData\\Local\\Temp\\ipykernel_6068\\2423478566.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['gender_by_txt'] = txt_model.predict(tfidf.transform(train.fullname + ' ' + train.username + ' ' + train.biography))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tfidf.fit(train.fullname + ' ' + train.username + ' ' + train.biography)\n",
    "txt_model.fit(tfidf.transform(x_train.fullname + ' ' + x_train.username + ' ' + x_train.biography), y_train)\n",
    "X['gender_by_txt'] = txt_model.predict(tfidf.transform(train.fullname + ' ' + train.username + ' ' + train.biography))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6988d0",
   "metadata": {},
   "source": [
    "### Second model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "972318f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y for new model based on predicted y from the last text based model \n",
    "\n",
    "X_sec = X[['gender_by_txt','len_bio','emoji_count','age','is_business','follower_count', 'following_count']]\n",
    "y_sec = train['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73bbec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benya\\AppData\\Local\\Temp\\ipykernel_6068\\3693932631.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_sec[numerical_col]=scaler.fit_transform(X_sec[numerical_col])\n"
     ]
    }
   ],
   "source": [
    "# Standardize numerical features\n",
    "\n",
    "numerical_col=['len_bio','emoji_count','age','follower_count', 'following_count']\n",
    "scaler = StandardScaler()\n",
    "X_sec[numerical_col]=scaler.fit_transform(X_sec[numerical_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d86dc5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benya\\AppData\\Local\\Temp\\ipykernel_6068\\1239527698.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_sec['gender_by_txt']=le.fit_transform(X_sec['gender_by_txt'])\n"
     ]
    }
   ],
   "source": [
    "# Encoding Label \n",
    "le = LabelEncoder()\n",
    "X_sec['gender_by_txt']=le.fit_transform(X_sec['gender_by_txt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8de7752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test Split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_sec, y_sec, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09a91cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.794375\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels 'man' and 'woman' to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(Y_train)\n",
    "y_val_encoded = label_encoder.transform(Y_val)\n",
    "\n",
    "# Model training with different hyperparameters\n",
    "xgb_classifier = XGBClassifier(\n",
    "    learning_rate=0.4,\n",
    "    max_depth=5,\n",
    "    n_estimators=150,\n",
    "    gamma=1,\n",
    "    random_state=42,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='error',\n",
    "    use_label_encoder=False\n",
    ")\n",
    "xgb_classifier.fit(X_train, y_train_encoded, eval_set=[(X_val, y_val_encoded)], verbose=False)\n",
    "\n",
    "# Predictions\n",
    "y_pred_encoded = xgb_classifier.predict(X_val)\n",
    "\n",
    "# Inverse transform the predicted numerical values to 'man' and 'woman'\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "#print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc432bc",
   "metadata": {},
   "source": [
    "#### The Accuracy of model on the final test data is : 80.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
